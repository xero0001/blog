---
title: ğŸ“ Linear Algebra - UNIT III - 08 Singular Value Decomposition and PCA
date: "2019-04-27S08"
tags: "ì„ í˜•ëŒ€ìˆ˜í•™"
---

[Learn Differential Equations: SVD](https://www.youtube.com/watch?v=mBcLRGuAFUk)

[Linear Algebra: Lec. 29](https://www.youtube.com/watch?v=Nx0lRBaXoz4&t=700s)

[SVD summary pdf](https://ocw.mit.edu/courses/mathematics/18-06sc-linear-algebra-fall-2011/positive-definite-matrices-and-applications/singular-value-decomposition/MIT18_06SCF11_Ses3.5sum.pdf)

[SVD Film](https://www.youtube.com/watch?v=R9UoFyqJca8)

[ë‹¤í¬í”„ë¡œê·¸ë˜ë¨¸ ë¸”ë¡œê·¸](https://darkpgmr.tistory.com/106)

---

# Singular Value Decomposition

ê°•ì˜ì—ì„œ ë‹¤ë£¨ëŠ” ë§ˆì§€ë§‰ì´ì ìµœê³ ì˜ factorizationì´ë‹¤!

## What is Singular Value Decomposition?

$$A= U \Sigma V^T$$

ìš°ë³€ì€ ê°ê° Orthogonal, Diagonal, Orthogonal Matrixë¡œ êµ¬ì„±ëœë‹¤.

Orthogonalê³¼ Diagonal ë‘˜ë‹¤ ì •ë§ ì¢‹ì€ íŠ¹ì„±ì„ ì§€ë‹ˆê³  ìˆë‹¤.

Orthogonalì€ ì—­í–‰ë ¬ì´ ì‰½ê²Œ êµ¬í•´ì§„ë‹¤.
Diagonalì€ ì œê³±ê³„ì‚°ì— ëŒ€í•´ ê°„ë‹¨í•˜ë‹¤.
(+Symmetricí•œ í–‰ë ¬ì€ eigenvectorê°€ orthogonalí•˜ë‹¤.)

**AëŠ” ì–´ë–¤ í–‰ë ¬ì´ì–´ë„ ìƒê´€ì—†ë‹¤. ì–´ë– í•œ Aë¼ë„ SVDë¥¼ ê°€ì§€ê³  ìˆë‹¤.**

ìƒˆë¡œìš´ ì ì€ ìš°ë¦¬ê°€ ì„œë¡œ ë‹¤ë¥¸ ë‘ê°œì˜ orthogonal matricesê°€ í•„ìš”í•˜ë‹¤ëŠ” ê²ƒì´ë‹¤.

ì´ ë¶„í•´ëŠ” ì´ ì½”ìŠ¤ì˜ ëª¨ë“  ê²ƒì„ í•¨ì¶•í•œë‹¤.

_ì‰½ê²Œ ë§í•˜ë©´ Eigendecompositionì˜ ì¼ë°˜í™”ë¼ê³  ë³¼ ìˆ˜ ìˆì„ ê²ƒ ê°™ë‹¤._

### Symmetric Positive Definitive

ë¨¼ì € ë¶ˆëŸ¬ì˜¬ ê²ƒì€ PDì´ë‹¤.

$$A=Q \Lambda Q^T$$

$$A=S \Lambda S^{-1}$$

Symmetricí•œ í–‰ë ¬ì€ Eigenvectorê°€ Orthogonalí•˜ë‹¤. ìœ„ì—ì„œ ì¼ë°˜ì ì¸ í–‰ë ¬ì¸ Sê°€ Qê°€ ëœ ê²ƒì„ ë³¼ ìˆ˜ ìˆë‹¤.

ê·¸ë¦¬ê³  PDì—ì„œ ì¼ë°˜ì ì¸ $$\Lambda$$ê°€ Positive $$\Lambda$$ê°€ ëœ ê²ƒì´ë‹¤.

$$A=Q \Lambda Q^T$$

í–‰ë ¬ì´ Symmetric Positive Definiteì¼ ê²½ìš° ìœ„ ì‹ì€ Singular Value Decompositionì„ í•œ ê²ƒê³¼ ê°™ë‹¤.  
Symmetric Positive Definiteì—ì„œëŠ” Uë‚˜ Vê°€ í•„ìš”ê°€ ì—†ë‹¤. ê·¸ëƒ¥ í•˜ë‚˜ì˜ Orthogonal matrixë©´ ì¶©ë¶„í•˜ë‹¤.

ê·¸ëŸ¬ë‚˜ ë‹¤ìŒì—ëŠ” í•´ë‹¹í•˜ì§€ ì•ŠëŠ”ë‹¤.

$$A=S \Lambda S^{-1}$$

ì¼ë°˜ì ìœ¼ë¡œ S í–‰ë ¬ì€ orthogonalí•˜ì§€ ì•Šë‹¤. ê·¸ë˜ì„œ ì´ëŠ” ì‹ ê²½ì“°ì§€ ì•Šê² ë‹¤.

Orthogonal x Diagonal x Orthogonal

ì¸ ê²½ìš°ë¥¼ ìƒê°í•˜ëŠ”ê²ƒì´ í¸í•˜ë‹¤.

ì´ê²Œ ì–´ë–¤ ì˜ë¯¸ë¥¼ ê°€ì§€ëŠ”ì§€, ì–´ë””ì„œ ì˜¨ê²ƒì¸ì§€ ì•Œì•„ë³´ì.

## How it works

![SVD](http://alexeygrigorev.com/projects/imsem-ws14-lina/img-svg/diagram3-svd.svg)

ìš°ë¦° í–‰ë ¬ Aë¥¼ row space $$R^n$$ì˜ ë²¡í„° $$v_1$$ì„ column space $$R^m$$ì˜ ë²¡í„°

$$u_1 = A v_1$$

ìœ¼ë¡œ ë³´ë‚´ëŠ” ê²ƒìœ¼ë¡œ ìƒê°í•  ìˆ˜ ìˆë‹¤.

SVDëŠ” row spaceì— ëŒ€í•œ orthogonal basisë¥¼ column spaceì— ëŒ€í•œ orthogonal basisë¡œ ë³€í™˜í•˜ëŠ” ê²ƒì—ì„œ ì¶œë°œí•œë‹¤.  
$$u$$ë¥¼ ë‹¨ìœ„ë²¡í„°ë¡œ ë§Œë“¤ì–´ orthonormalí•˜ê²Œ í‘œí˜„í•˜ê¸° ìœ„í•´ ë‹¤ìŒì²˜ëŸ¼ $$\sigma$$ë¥¼ ì¶”ê°€í•˜ì—¬ ìŠ¤ì¼€ì¼ë§ í•´ì¤€ë‹¤.

$$Av_i = \sigma_i u_i$$

Row spaceì— ëŒ€í•œ orthonormal basisë¥¼ ì°¾ëŠ” ê²ƒì€ ì–´ë µì§€ ì•Šì€ ì¼ì´ë‹¤ - Gram Schmidt processë¥¼ ì´ìš©í•œë‹¤ë©´.  
ê·¸ëŸ¬ë‚˜ ê·¸ orthogonal basisë¥¼ ë˜ ë‹¤ë¥¸ ê³µê°„ì˜ orthogonal basisë¥¼ ë³´ë‚¸ë‹¤ê³  ê·¸ê²ƒì´ orthogonalì´ë¼ëŠ” ë³´ì¥ì´ ì—†ë‹¤.  
ê·¸ë ‡ê¸° ë•Œë¬¸ì— íŠ¹ë³„í•œ setupì´ í•„ìš”í•˜ë‹¤.

$$A,A^T$$ì˜ Nullspaceìƒì— ìˆëŠ” ë²¡í„°ë“¤ì— ëŒ€í•´ ê±±ì •í• ì§€ë„ ëª¨ë¥´ì§€ë§Œ ìƒê´€ì—†ë‹¤.  
$$\Sigma$$ì˜ ëŒ€ê°ì„±ë¶„ $$\sigma_{r+1},\sigma_{r+2},...\sigma_{n}$$ëŠ” 0ìœ¼ë¡œ ë‚˜íƒ€ë‚  ê²ƒì´ê¸° ë•Œë¬¸ì´ë‹¤.  
ê·¸ëŸ¬ë¯€ë¡œ í‘œì‹œí•˜ì§€ ì•Šì•„ë„ ëœë‹¤.

## Matrix language

ì´ë¥¼ í–‰ë ¬ì‹ìœ¼ë¡œ í‘œí˜„í•´ë³´ì.

ì•ìœ¼ë¡œ $$\Lambda$$ëŒ€ì‹ ì— $$\Sigma$$ë¼ê³  ë¶€ë¥¼ê²ƒì´ë‹¤.

$$
A
\begin{bmatrix}
v_1 & v_2 & \cdots & v_r
\end{bmatrix}
=
\begin{bmatrix}
\sigma_1 u_1 & \sigma_2u_2 & \cdots & \sigma_ru_r
\end{bmatrix}
\\\\
=
\begin{bmatrix}
u_1 & u_2 & \cdots & u_r
\end{bmatrix}
\begin{bmatrix}
\sigma_1 & & & \\
 & \sigma_2 & & \\
 &  & \ddots & \\
 &  & & \sigma_r \\
\end{bmatrix}
$$

$$\sigma$$ëŠ” ë‹¨ìœ„ë²¡í„° $$u$$ë¥¼ ìŠ¤ì¼€ì¼ë§í•˜ê¸° ìœ„í•œ ê²ƒì´ë‹¤.

ë¬¸ì œì˜ í•µì‹¬ì€ í–‰ë ¬ Aì— ëŒ€í•´ column spaceìƒì˜ orthonormal basis $$u_1,u_2,...u_r$$ë¡œ ë³€í™˜ ë˜ëŠ” row spaceìƒì˜ orthonormal basis $$v_1,v_2,...v_r$$ë¥¼ ì°¾ëŠ” ê²ƒì´ë‹¤.

Null spaceê¹Œì§€ í¬í•¨í•´ì„œ ì´ë¥¼ ë‹¤ì‹œ ì •ë¦¬í•˜ë©´

$$AV=U \Sigma$$

ê°€ ëœë‹¤.

Orthonormal basis $$V$$ in row space, orthonormal basis $$U$$ in column space. ì´ ë‘˜ì„ ì´ìš©í•˜ì—¬ í–‰ë ¬ì„ ëŒ€ê°í™”í•˜ì˜€ë‹¤.  
í–‰ë ¬ Aê°€ ëŒ€ê°í™”ëœ í–‰ë ¬ë¡œ í‘œí˜„ëœ ê²ƒì´ë‹¤.

ì¼ë°˜ì ìœ¼ë¡œëŠ” Uì™€ VëŠ” ì„œë¡œ ë‹¤ë¥¸ í–‰ë ¬ì´ë‹¤.  
ê·¸ëŸ¬ë‚˜ Positive definiteì˜ ê²½ìš°ëŠ”

$$AQ=Q \Sigma$$

ì¸ ê²½ìš°ë‹¤.  
Vì™€ Uê°€ ë˜‘ê°™ì´ Qì¸ ê²ƒì´ë‹¤.  
ì¦‰, ê°™ì€ basisë¥¼ row ì™€ column spaceì— ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤.

## Calculation

$$
A
=
\begin{bmatrix}
4 & 4 \\
-3 & 3
\end{bmatrix}
$$

ì´ëŠ” invertibleí•˜ê³  rank 2ë¥¼ ê°€ì§„ë‹¤.  
ê·¸ëŸ¬ë‚˜ symmetricí•˜ì§€ ì•Šì•„ì„œ eigenvectorê°€ orthogonalí•˜ì§€ ì•Šì•„ ê·¸ëŒ€ë¡œ ì´ìš©í•  ìˆ˜ ì—†ë‹¤.

row space $$R^2$$ì—ì„œ $$v_1,v_2$$ë¥¼ ì°¾ê³ , column space $$R^2$$ì—ì„œ $$u_1,u_2$$ë¥¼ ì°¾ì•„ë³´ì.  
ê·¸ë¦¬ê³  $$\sigma_1 \gt 0,\sigma_2 \gt 0$$ë¥¼ ì°¾ì•„ $$v_i,u_i$$ì„ orthonormalí•˜ê²Œ ë§Œë“¤ì.

ë‹¤ìŒì— ëŒ€í•œ Orthonormal í–‰ë ¬ V,U, Diagonal í–‰ë ¬ $$\Sigma$$ë¥¼ ì°¾ì•„ë³´ì.

$$AV=U \Sigma$$

$$V$$ê°€ orthogonalí•˜ë¯€ë¡œ $$V^{-1}=V^T$$ ë¡œ ì–‘ë³€ì— ê³±í•œë‹¤.

$$A=U \Sigma V^T$$

$$U,V$$ì™€ $$\Sigma$$ ë¥¼ ë™ì‹œì— í’€ê¸°ë³´ë‹¨, ì–‘ë³€ì— $$A^T=V \Sigma^T U^T$$ë¥¼ ê³±í•˜ì—¬ Uë¥¼ ì—†ì• ì:

$$
A^TA = V \Sigma U^{-1} U \Sigma V^T \\\\
=V \Sigma^2 V^T \\\\
= V
\begin{bmatrix}
\sigma_1^2 & & & \\
 & \sigma_2^2 & & \\
& & \ddots & \\
 & & & \sigma_n^2 \\
\end{bmatrix}
V^T
$$

$$A^TA$$ëŠ” Symmetricí•˜ë©°, positive definite í˜¹ì€ semidefiniteì´ë‹¤.

ì´ê²ƒì€ $$Q \Lambda Q^T$$í˜•íƒœë¼ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤.  
ê·¸ëŸ¬ë¯€ë¡œ í–‰ë ¬ $$A^TA$$ë¥¼ ëŒ€ê°í™”í•¨ìœ¼ë¡œì¨ Vë¥¼ ì°¾ì„ ìˆ˜ ìˆë‹¤.  
$$V$$ì˜ columnë“¤ì€ $$A^TA$$ì˜ eigenvectorë“¤ì´ê³ , positive definiteì´ê¸° ë•Œë¬¸ì— $$\sigma_i^2$$ëŠ” ì–‘ìˆ˜ì¸ eigenvalueë“¤ì´ë‹¤.($$\sigma_i$$ëŠ” ì–‘ìˆ˜ì¸ $$\lambda_i$$ì˜ ì œê³±ê·¼ì„ ì„ íƒí•˜ë©´ ëœë‹¤.)

$$U$$ë¥¼ ì–»ê¸° ìœ„í•´ì„œ ìš°ë¦¬ëŠ” $$AA^T$$ì— ëŒ€í•´ ê°™ì€ ê²ƒì„ í•˜ë©´ëœë‹¤.

## SVD example

$$
A=
\begin{bmatrix}
4 & 4 \\
-3 & 3
\end{bmatrix}
$$

ë‹¤ì‹œ ëŒì•„ì™€ì„œ ê³„ì‚°í•´ë³´ì.

$$
A^TA =
\begin{bmatrix}
25 & 7 \\
7 & 25
\end{bmatrix}
$$

EigenvectorëŠ” $$v_i$$ê°€ ë ê²ƒì´ê³ , eigenvalueëŠ” $$\sigma_i$$ê°€ ë ê²ƒì´ë‹¤.

$$
v_1=
\begin{bmatrix}
1/\sqrt{2}\\
1/\sqrt{2}
\end{bmatrix}
, v_2=
\begin{bmatrix}
1/\sqrt{2}\\
-1/\sqrt{2}
\end{bmatrix}
$$

$$\sigma_1^2=32,\sigma_2^2=18$$

$$A=U \Sigma V^T$$

$$
\begin{bmatrix}
4 & 4\\
-3 & 3
\end{bmatrix}
=
\begin{bmatrix}
 \\

\end{bmatrix}
\begin{bmatrix}
4 \sqrt{2} & 0\\
0 & 3 \sqrt{2}
\end{bmatrix}
\begin{bmatrix}
1/\sqrt{2} & 1/\sqrt{2}\\
1/\sqrt{2} & -1/\sqrt{2}
\end{bmatrix}
$$

ì´ë¥¼ í†µí•´ Uë¥¼ í’€ ìˆ˜ ìˆìœ¼ë‚˜, ì—°ìŠµì„ ìœ„í•´ $$AA^T$$ë¡œë„ í•´ë³´ë©´ ì¢‹ë‹¤.

$$A^TA$$ì˜ eigenvalueì™€ $$AA^T$$ì˜ eigenvalueëŠ” ê°™ë‹¤.

## Example with a nullspace

$$
A=
\begin{bmatrix}
4 & 3 \\
8 & 6
\end{bmatrix}
$$

---

# Principle Component Analysis

Symmetricí•œ Aì— ëŒ€í•´ Eigendecompositionì„ í•˜ë©´,

$$A=S \Lambda S^T$$

SëŠ” orthonormalí•˜ë‹¤.

_ê°œì¸ì ì¸ í•´ì„ì€ ì´ëŠ” otrhonormal eigenvectorì¸ Sì˜ basisë¡œ ë³€í™˜í•˜ê³ , $$\Lambda$$ì˜ eigenvalueë§Œí¼ ìŠ¤ì¼€ì¼ë§ í•´ì¤€ë’¤, ë‹¤ì‹œ ì›ë˜ëŒ€ë¡œ Sì˜ ì—­ë³€í™˜ì„ í•´ì£¼ëŠ” ëŠë‚Œì¸ê²ƒ ê°™ë‹¤. ë¬¼ë¡  ê³±í•´ì§€ëŠ” ìˆœì„œëŠ” ê·¸ ë°˜ëŒ€ê¸´í•˜ì§€ë§Œ._

![81](/assets/figures/math/LA8-1.PNG)

eigenvalueê°€ ì œì¼ ì‘ì€ ì„±ë¶„ì„ 0ìœ¼ë¡œ ë§Œë“¤ì–´ë²„ë¦¬ë©´, ì›ë˜ì˜ ë²¡í„°ì™€ ì˜¤ì°¨ê°€ í¬ì§€ ì•Šë‹¤.

eigenvalueë§Œí¼ ë³€í˜•ì„ í•˜ê²Œ ë˜ëŠ”ë°, ê·¸ ë³€í˜•ì˜ ì •ë„ê°€ ì œì¼ ì‘ì€ ê²ƒì„ 0ìœ¼ë¡œ ë§Œë“¤ì–´ë„ ê·¸ëŸ­ì €ëŸ­ ì›ë˜ì™€ ë¹„ìŠ·í•˜ê²Œ ì¬êµ¬ì„±í•  ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì´ë‹¤.

ì´ëŸ¬í•œ íŠ¹ì§•ì„ ì´ìš©í•˜ë©´ Rankê°€ ë” ë‚®ì€ Low Dimensional Representationì„ ì–»ì„ ìˆ˜ ìˆë‹¤.

ë‚®ì€ ì°¨ì›ì˜ hyperplaneìœ¼ë¡œ íˆ¬ì˜ë˜ëŠ” ê²ƒì´ë‹¤.

## Covariance, Covariance Matrix

$$cov(X,Y)=\sigma_{X,Y}^2 = E(XY)- \mu_X \mu_Y$$

$$=E((X-\mu_X)(Y-\mu_Y))=\frac{1}{n-1}\sum_{i=1}^{n} (x_i - \mu_X)(y_i - \mu_Y)$$

nê°œì˜ ë°ì´í„°ì— ëŒ€í•´ ì „ë¶€ í‰ê· .

![82](/assets/figures/math/LA8-2.PNG)

CovëŠ” Symmetricí•˜ë‹¤. ì´ëŠ” ê·¸ ì •ì˜ì— ì˜í•´ ì¦ëª…ëœë‹¤.

![83](/assets/figures/math/LA8-3.PNG)

ì›í˜•ì´ë¼ë©´ ëŒ€ê°í–‰ë ¹ì˜ ëŒ€ê° ì›ì†Œê°€ ëª¨ë‘ ê°™ë‹¤.

ëŒ€ê° í–‰ë ¬ì˜ ëŒ€ê° ì„±ë¶„ì´ ì„œë¡œ ë‹¤ë¥´ë‹¤ë©´ í•œìª½ìœ¼ë¡œ ëŠ˜ì–´ì ¸ìˆë‹¤. íƒ€ì›ì²´(ellipsoid) ëª¨ì–‘ì¼ë“¯?

ëŒ€ê° í–‰ë ¬ì´ ì•„ë‹ˆê³  ì¼ë°˜ì ì¸ í–‰ë ¬ì´ë¼ë©´ íšŒì „í•œ íƒ€ì›ì²´ ëª¨ì–‘.

_í‰ê· ê³¼ ë¶„ì‚°ì„ ì •ê·œë¶„í¬ë¡œ ëª¨ë¸ë§ í–ˆì„ ë•Œ ìœ„ì²˜ëŸ¼ ë³´ì´ê²Œ ë˜ëŠ”ë“¯. ë¬¼ë¡  ìˆ˜ê°€ ëŠ˜ì–´ë‚˜ë©´ CLTì— ì˜í•´ ë§ˆì°¬ê°€ì§€ê°€ ë˜ê² ì§€ë§Œ._

kì°¨ì›ì¸ nê°œì˜ ë°ì´í„°ì— ëŒ€í•´ ê°ê°ì˜ 1ë¶€í„° kê¹Œì§€ì˜ ì¶•ì˜ ë°ì´í„°ì˜ í‰ê· ì„ 0ì´ë¼ê³  í•  ë•Œ, (Normalize í•˜ì˜€ì„ ë•Œ?) ì´ ê³µë¶„ì‚° í–‰ë ¬ì„ êµ¬í•˜ëŠ” ê²ƒì€ ì‰¬ì›Œì§„ë‹¤.

![84](/assets/figures/math/LA8-4.PNG)

í‰ê· ì´ 0ì´ë¼ ì‰½ê²Œ ì—°ì‚°í•  ìˆ˜ ìˆë‹¤.

![85](/assets/figures/math/LA8-5.PNG)

ì´ì œ ì´ ê³µë¶„ì‚° í–‰ë ¬ì„ ì°¨ì› ì¶•ì†Œì‹œì¼œ íˆ¬ì˜í•  ê²ƒì´ë‹¤.

í‰í–‰ì´ë™ í•˜ëŠ” ê²ƒì€ ê°„ë‹¨í•œ ì¼ì´ë‹¤.

ê·¸ëŸ¬ë‚˜ íšŒì „ì´ ì–´ë µë‹¤. ì–¼ë§ˆë‚˜ íšŒì „ì‹œì¼œì•¼í• ê¹Œ?

![86](/assets/figures/math/LA8-6.PNG)

ê³µë¶„ì‚° í–‰ë ¬ì´ ëŒ€ê°í™”ë  ë•Œ ê¹Œì§€ íšŒì „í•˜ëŠ” ê²ƒì´ë‹¤.

(ê¸¸ë²„íŠ¸ êµìˆ˜ë‹˜ì´ Spectral Theorem ì„¤ëª…í•  ë•Œ ì–´ë–¤ ê°ë„ì—ì„œ ë³´ë©´ 'ìˆœìˆ˜í•œ ì„±ë¶„'ì´ ë³´ì¸ë‹¤ëŠ” ëœ»ì´ ì´ê²ƒì´ë‹¤.)

ì´ë¥¼ ìˆ˜ì‹í™”í•˜ë©´, íšŒì „ ì „ í–‰ë ¬ì„ X, íšŒì „ í›„ í–‰ë ¬ì„ Yë¼ê³  í–ˆì„ ë•Œ

$$Y=PX$$

ì¸ íšŒì „í–‰ë ¬ $$P$$ë¥¼ ì–»ê² ë‹¤ëŠ” ê²ƒì´ë‹¤.

![87](/assets/figures/math/LA8-7.PNG)

$$P=S^T$$ ë¡œ ë‘ë©´ $$\Lambda$$ë§Œ ì™ ë¹ ì§€ê³  ë‚˜ë¨¸ì§€ê°€ ì—†ì–´ì§„ë‹¤.

_$$X^TX$$ì´ ê³µë¶„ì‚° í–‰ë ¬ì´ë¼ëŠ” ê²ƒì€ ë§¤ìš° ì¢‹ë‹¤. Symmetricí•´ì„œ eigenvectorê°€ ì „ë¶€ ì§êµí•˜ê¸° ë•Œë¬¸ì´ë‹¤. ê·¸ëŸ°ë° ê³µë¶„ì‚°ì´ë¼ëŠ” ì˜ë¯¸ê¹Œì§€ ê°€ì§„ë‹¤.._

![88](/assets/figures/math/LA8-8.PNG)

eigenvalueê°€ ì‘ì€ ê²ƒì„ ì‚­ì œí•˜ë©´ ì°¨ì›ì¶•ì†Œê°€ ëœë‹¤.
